{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Binary Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","dsMeta = pd.read_csv('/kaggle/input/datasetfinals/train/train_meta.csv')\n","dsMeta"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsMeta.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsMeta.set_index('record_name', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsTrue = pd.read_csv('/kaggle/input/datasetfinals/train/train_gts.csv')\n","dsTrue"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsTrue.set_index('record_name', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np                      ## загрузка экг данных\n","train_X = []           \n","train_Y = []\n","for key in list(dsTrue.index):\n","  train_X.append(np.load('/kaggle/input/datasetfinals/train/'+key+'.npy'))\n","  per = dsMeta.loc[key]\n","  per['y'] = dsTrue.loc[key]['myocard']\n","  train_Y.append(per)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler            ## нормализование данных\n","import numpy as np\n","\n","\n","all_data = np.concatenate(train_X, axis=0)\n","print(all_data.shape)\n","\n","scaler = StandardScaler()\n","scaler.fit(all_data)\n","\n","normalized_data_list = [scaler.transform(data) for data in train_X]\n","\n","train_X = normalized_data_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split  ## деление данных\n","\n","splitted_data = train_test_split(train_X, train_Y, test_size=0.1,random_state=48)\n","X_train_first, X_train_second, y_train_first, y_train_second = splitted_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X_train_first = train_X                ## обучение на полном датасете\n","# y_train_first = train_Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","X = torch.from_numpy(np.array(X_train_first))\n","y = torch.from_numpy(np.array([i['y'] for i in y_train_first]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_slices = []                                ## аугментирование данных: деление на кусочки по 800 измерений\n","y_slices = []\n","#cat_slices = []\n","#fullX_slices = []\n","step = 100\n","for i in range(0, 5000-800, step): #Скольжение окном с шагом 100 по 800 измерений\n","    X_slices.append(X[:,:,i:i+800])\n","    y_slices.append(y)\n","\n","X_new = torch.cat(X_slices, dim=0)\n","y_new = torch.cat(y_slices, dim=0)\n","X_new.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","dataset = TensorDataset(X_new, y_new)\n","\n","batch_size = 128\n","\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ECG_CNN_TransformerBIN(nn.Module):\n","    def __init__(self):\n","        super(ECG_CNN_TransformerBIN, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=12, out_channels=64, kernel_size=7, padding=3)\n","        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n","        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1,)\n","\n","        self.encoder_layer = nn.TransformerEncoderLayer(d_model=12, nhead=3)\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n","\n","        self.fc1 = nn.Linear(256*800 + 12*800 , 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.relu = nn.ReLU()\n","        self.sig = nn.Sigmoid()\n","        self.drop = nn.Dropout(0.2)\n","        self.drop5 = nn.Dropout(0.8)\n","\n","    def forward(self, x):\n","        cnn_x = self.relu(self.conv1(x))\n","        cnn_x = self.relu(self.conv2(cnn_x))\n","        cnn_x = self.relu(self.conv3(cnn_x))\n","        cnn_x = cnn_x.view(x.size(0), -1)\n","\n","        #cnn_xf = self.relu(self.conv1(full_x))\n","        #cnn_xf = cnn_xf.view(full_x.size(0), -1)\n","        #cnn_xf = self.drop5(cnn_xf)\n","\n","        x = x.permute(2, 0, 1)\n","        transformer_x = self.transformer_encoder(x)\n","        transformer_x = transformer_x.permute(1, 0, 2)\n","        transformer_x = transformer_x.reshape(transformer_x.size(0), -1)\n","        #transformer_x = self.drop(transformer_x) #drop показал себя хуже\n","\n","        #Конкатинируем результаты cnn и transformer слоёв\n","        x = torch.cat((cnn_x, transformer_x), dim=1)\n","\n","        x = self.relu(self.fc1(x))\n","        #x = self.drop(x)\n","        x = self.fc2(x)\n","        #x = self.sig(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","import sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#del model\n","torch.cuda.empty_cache()\n","modelBIN = ECG_CNN_TransformerBIN().cuda()\n","\n","#WithLogits показал себя лучше\n","loss_function = nn.BCEWithLogitsLoss()\n","\n","optimizer = optim.AdamW(modelBIN.parameters(), lr=0.000001)\n","from torch.optim import lr_scheduler\n","#scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.0000003)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference_ov(model, x, overlap=0.875):\n","    num_windows = int((x.shape[1] * overlap) // 800) + (1 if (x.shape[1] * overlap) % 800 != 0 else 0)\n","    step_size = int(800 * overlap)\n","    preds = []\n","\n","    with torch.no_grad():\n","        model.eval()\n","\n","        for i in range(num_windows):\n","            start = i * step_size\n","            end = start + 800\n","            x_window = x[:, start:end]\n","            pred = model(x_window.unsqueeze(0))\n","            preds.append(pred.item())\n","\n","        avg_pred = sum(preds) / num_windows\n","\n","    return avg_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def add_noise(seq, target, noise_weight=0.05):\n","    noise = torch.randn_like(seq) * noise_weight\n","\n","    seq_noisy = seq + noise\n","\n","    seq = torch.cat((seq, seq_noisy), dim=0)\n","    target = torch.cat((target, target), dim=0)  \n","\n","    return seq, target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["best_model = ''     ## обучение модели\n","f1Max = 0\n","from copy import deepcopy\n","\n","loss_arr = []\n","epoch_qty = 100 #Кол-во эпох\n","for epoch in range(epoch_qty):\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    for iter, (seq, target) in enumerate(tqdm(dataloader)):\n","        seq, target = add_noise(seq, target, 0.05) #Добавление шума\n","\n","        y_pred = modelBIN(seq.cuda())\n","\n","        loss = loss_function(y_pred.squeeze().cuda(), target.float().cuda())\n","        loss_arr.append(loss.item())\n","        loss.backward()\n","        optimizer.step()\n","\n","#     eval_res = []                     ## evaluation модели если есть валидационная часть\n","#     for x in range(len(X_train_second)):\n","#        eval_res.append(inference_ov(model, torch.from_numpy(X_train_second[x]).cuda()))\n","#     f1 = sklearn.metrics.f1_score([i['y'] for i in y_train_second],[1 if float(i) >= 0.275 else 0 for i in eval_res])\n","#     print(f1)\n","#     if f1 > f1Max:\n","#         best_model = deepcopy(model.state_dict())\n","#         f1Max = f1\n","      \n","    \n","    print(sum(loss_arr)/len(loss_arr))\n","    if sum(loss_arr)/len(loss_arr) <= 0.03: #При данном значении результат на паблике и вале был наилучшим\n","      break\n","    loss_arr = []\n","    if (epoch+1) % 10 == 0:\n","      print(f'Epoch: {epoch}, Loss: {str(loss.item())}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#best_modelBIN = deepcopy(best_model)\n","# torch.save(modelBIN.state_dict(), '3heads1layerONFULLSET0.02lossBIN.pt')"]},{"cell_type":"markdown","metadata":{},"source":["# 6 Classes Model"]},{"cell_type":"markdown","metadata":{},"source":["Данные открываются сначала и некоторые библиотеки импортируются заново, так как обучение 2х моделей производилось и по отдельности"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","dsMeta = pd.read_csv('/kaggle/input/datasetfinals/train/train_meta.csv')\n","dsMeta"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsMeta.set_index('record_name', inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","dsTrue = pd.read_csv('/kaggle/input/datasetfinals/train/train_gts_final.csv')\n","dsTrue"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsTrue.set_index('record_name', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from copy import copy\n","train_X = []\n","train_Y = []\n","for key in list(dsTrue.index):\n","  train_X.append(np.load('/kaggle/input/datasetfinals/train/'+key+'.npy'))\n","  per = dsMeta.loc[key].copy()\n","#   print(list(dsTrue.loc[key]))\n","  per['y'] = list(dsTrue.loc[key])\n","  train_Y.append(per['y'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","all_data = np.concatenate(train_X, axis=0)\n","print(all_data.shape)\n","\n","scaler = StandardScaler()\n","scaler.fit(all_data)\n","\n","normalized_data_list = [scaler.transform(data) for data in train_X]\n","\n","train_X = normalized_data_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","splitted_data = train_test_split(train_X, train_Y, test_size=0.1,random_state=48)\n","X_train_first, X_train_second, y_train_first, y_train_second = splitted_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X_train_first = train_X      ##обучение на полном датасете\n","# y_train_first = train_Y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","X = torch.from_numpy(np.array(X_train_first))\n","y = torch.from_numpy(np.array(y_train_first))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from tqdm import tqdm\n","# def add_noise_to_sample(sample, noise_level=0.001):\n","#     noise = torch.randn_like(sample) * noise_level\n","#     return sample + noise\n","\n","# lengthh = X.shape[0]                         ##Применение заранее шума к обычным данным не дало прироста F1\n","# new_X_balanced = []\n","# new_y_balanced = []\n","# for xx in tqdm(range(lengthh)):\n","# #     print(xx)\n","#     sample_X_balanced = X[xx]\n","#     new_X_balanced.append(add_noise_to_sample(sample_X_balanced))\n","#     new_X_balanced.append(sample_X_balanced)\n","    \n","#     new_y_balanced.append(y[xx])\n","#     new_y_balanced.append(y[xx])\n","    \n","# X = torch.stack(new_X_balanced, dim = 0)\n","# y = torch.stack(new_y_balanced, dim = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_slices = []\n","y_slices = []\n","\n","step = 50\n","for i in range(0, 5000-700, step): \n","    X_slices.append(X[:,:,i:i+700])\n","    y_slices.append(y)\n","\n","X_new = torch.cat(X_slices, dim=0)  \n","y_new = torch.cat(y_slices, dim=0) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sum_first_6_classes = 0#sum(counts[:-1])  # используя вашу переменную counts\n","\n","# Индексы для каждого класса\n","indices = [torch.where(y_new[:,i]==1)[0] for i in range(y_new.shape[1])]\n","\n","# Получаем случайную перестановку индексов для последнего класса и берем нужное количество\n","random_indices_last_class = indices[-1][torch.randperm(len(indices[-1]))[:sum_first_6_classes]]\n","\n","# Индексы для нового массива данных\n","new_indices = torch.cat(indices[:-1] + [random_indices_last_class])\n","\n","# Новые данные\n","X_balanced = X_new[new_indices]\n","y_balanced = y_new[new_indices]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_balanced = torch.tensor([[int(b) for b in i[:6]] for i in y_balanced])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","dataset = TensorDataset(X_balanced, y_balanced)\n","\n","batch_size = 128\n","\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X2 = []\n","Y2 = []\n","\n","for i in range(len(X_train_second)):\n","    if y_train_second[i][-1] != 1:\n","        X2.append(X_train_second[i])\n","        Y2.append(y_train_second[i][:6])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference_ov(model, x, overlap=0.875):\n","    num_windows = int((x.shape[1] * overlap) // 700) + (1 if (x.shape[1] * overlap) % 700 != 0 else 0)\n","    step_size = int(700 * overlap)\n","    preds = []\n","    \n","    with torch.no_grad():\n","        model.eval()\n","        \n","        for i in range(num_windows):\n","            start = i * step_size\n","            end = start + 700\n","            x_window = x[:, start:end]\n","            pred = model(x_window.unsqueeze(0))\n","            preds.append(pred)\n","        \n","        avg_pred = sum(preds) / num_windows\n","        \n","    return avg_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","def sigmoid(x):\n","    return 1 / (1 + math.exp(-x))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ECG_CNN_Transformer(nn.Module):\n","    def __init__(self):\n","        super(ECG_CNN_Transformer, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=12, out_channels=64, kernel_size=7, padding=3)\n","        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n","        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1,)\n","        \n","        self.encoder_layer = nn.TransformerEncoderLayer(d_model=12, nhead=2)\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n","        #+ 64*1000\n","        self.fc1 = nn.Linear(256*700 + 12*700 , 128) \n","        self.fc2 = nn.Linear(128, 6)\n","        self.relu = nn.ReLU()\n","        self.sig = nn.Sigmoid()\n","        self.drop = nn.Dropout(0.2)\n","        self.drop5 = nn.Dropout(0.8)\n","\n","    def forward(self, x):\n","        cnn_x = self.relu(self.conv1(x))\n","        cnn_x = self.relu(self.conv2(cnn_x))\n","        cnn_x = self.relu(self.conv3(cnn_x))\n","        cnn_x = cnn_x.view(x.size(0), -1) \n","\n","        x = x.permute(2, 0, 1)  \n","        transformer_x = self.transformer_encoder(x)\n","        transformer_x = transformer_x.permute(1, 0, 2) \n","        transformer_x = transformer_x.reshape(transformer_x.size(0), -1)  \n","        #transformer_x = self.drop(transformer_x)\n","\n","        # Concatenate CNN and Transformer outputs\n","        x = torch.cat((cnn_x, transformer_x), dim=1)\n","\n","        x = self.relu(self.fc1(x))\n","        #x = self.drop(x)\n","        x = self.fc2(x)\n","        #x = self.sig(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","import sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# del model\n","torch.cuda.empty_cache()\n","model = ECG_CNN_Transformer().cuda()\n","optimizer = optim.AdamW(model.parameters(), lr=0.000001)\n","from torch.optim import lr_scheduler\n","\n","loss_function = nn.BCEWithLogitsLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# checkpoint16102023 = torch.load('/kaggle/input/fullf10-54loss0-14classes6/FULLf10.54loss0.14classes6.pt')\n","# model = ECG_CNN_Transformer().cuda()\n","# model.load_state_dict(checkpoint16102023.state_dict())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def add_noise(seq, target, noise_weight=0.05):\n","    noise = torch.randn_like(seq) * noise_weight\n","\n","    seq_noisy = seq + noise\n","\n","    seq = torch.cat((seq, seq_noisy), dim=0)\n","    target = torch.cat((target, target), dim=0)  \n","\n","    return seq, target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["f1Max = 0\n","bestModel = ''\n","from copy import deepcopy\n","loss_arr = []\n","for epoch in range(200):\n","    \n","    model.train(True)\n","    \n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","    \n","    for iter, (seq, target) in enumerate(tqdm(dataloader)):\n","        seq, target = add_noise(seq, target, 0.05) #Добавление шума\n","        \n","        y_pred = model(seq.cuda())\n","        loss = loss_function(y_pred.cuda(), target.float().cuda())\n","        loss.backward()\n","        \n","        optimizer.step()\n","\n","        loss_arr.append(loss.item())\n","\n","\n","#     model.eval()\n","#     eval_res = []\n","#     for x in range(len(X2)):\n","#        eval_res.append(inference_ov(model, torch.from_numpy(X2[x]).cuda()))\n","# #            print(eval_res)\n","#     new_arr = []\n","#     for k in range(len(eval_res)):\n","#         for j in range(len(eval_res[k])):\n","#             new_arr.append(eval_res[k][j].detach().cpu().numpy())\n","#     new_arr = [[sigmoid(j) for j in i] for i in new_arr]\n","#     f1 = sklearn.metrics.f1_score(Y2,[[1 if float(j) >= 0.20 else 0 for j in i]for i in new_arr], average = 'macro')\n","#     print(f\"F1_score = {f1}\")\n","#     if f1 > f1Max:\n","#         f1Max = f1\n","#         bestModel = deepcopy(model.state_dict())\n","#     print(f\"F1_score = {f1}\")\n","\n","    \n","\n","    print(sum(loss_arr)/len(loss_arr))\n","    \n","    if sum(loss_arr)/len(loss_arr) <= 0.15: #При данном значении результат был наилучшим\n","      break\n","    loss_arr = []\n","\n","    print(f'Epoch: {epoch}, Loss: {str(loss.item())}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.eval()       ## evalutation модели и перебор лучшего трешхолда\n","eval_res = []\n","for x in range(len(X2)):\n","   eval_res.append(inference_ov(model, torch.from_numpy(X2[x]).cuda()))\n","\n","new_arr = []\n","for k in range(len(eval_res)):\n","    for j in range(len(eval_res[k])):\n","        new_arr.append(eval_res[k][j].detach().cpu().numpy())\n","new_arr = [[sigmoid(j) for j in i] for i in new_arr]\n","sklearn.metrics.f1_score(Y2,[[1 if float(j) >= 0.1 else 0 for j in i]for i in new_arr], average = 'macro')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# torch.save(model.state_dict(), 'classes6heads2ONFULLSET0.12loss.pt')"]},{"cell_type":"markdown","metadata":{},"source":["# Работа с тестовыми данными и создание сабмита"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","dsMetatest = pd.read_csv('/kaggle/input/datasetfinalstest/test/test_meta.csv')\n","dsMetatest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["record_names = list(dsMetatest['record_name'])\n","from copy import copy\n","y_train_secondtest = copy(dsMetatest)\n","dsMetatest.set_index('record_name', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","test_X = []\n","test_meta = []\n","\n","for key in record_names:\n","  test_X.append(np.load('/kaggle/input/datasetfinalstest/test/'+key+'.npy'))\n","  test_meta.append(dsMetatest.loc[key])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","normalized_data_listtest = [scaler.transform(data) for data in test_X]\n","\n","test_X = normalized_data_listtest"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsMetaTest = pd.read_csv('/kaggle/input/datasetfinalstest/test/test_meta.csv')\n","train_record_names = dsMetaTest['record_name']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference_ov(model, x, overlap=0.875):\n","    num_windows = int((x.shape[1] * overlap) // 800) + (1 if (x.shape[1] * overlap) % 800 != 0 else 0)\n","    step_size = int(800 * overlap)\n","    preds = []\n","        \n","    with torch.no_grad():\n","        model.eval()\n","        \n","        for i in range(num_windows):\n","            start = i * step_size\n","            end = start + 800\n","            x_window = x[:, start:end]\n","            pred = model(x_window.unsqueeze(0))\n","            preds.append(pred)\n","        \n","        avg_pred = sum(preds) / num_windows\n","        \n","    return avg_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# modelBIN = ECG_CNN_TransformerBIN().cuda()\n","# modelBIN.load_state_dict(torch.load('/kaggle/input/balancedbin0-09loss2heads1layer/balancedBIN0.09loss2heads1layer.pt').state_dict())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["eval_res = []\n","for x in range(len(test_X)):\n","   eval_res.append(inference_ov(modelBIN, torch.from_numpy(test_X[x]).cuda()))\n","eval_res = [sigmoid(i) for i in eval_res]\n","# print(sklearn.metrics.f1_score([i['y'] for i in y_train_second],[1 if float(i) >= 0.325 else 0 for i in eval_res]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference_ov(model, x, overlap=0.875):\n","    num_windows = int((x.shape[1] * overlap) // 700) + (1 if (x.shape[1] * overlap) % 700 != 0 else 0)\n","    step_size = int(700 * overlap)\n","    preds = []\n","    \n","    with torch.no_grad():\n","        model.eval()\n","        \n","        for i in range(num_windows):\n","            start = i * step_size\n","            end = start + 700\n","            x_window = x[:, start:end]\n","            pred = model(x_window.unsqueeze(0))\n","            preds.append(pred)\n","        \n","        avg_pred = sum(preds) / num_windows\n","        \n","    return avg_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# checkpoint = torch.load('/kaggle/input/classes6heads2onfullset0-085loss/classes6heads2ONFULLSET0.085loss.pt')\n","# model  = ECG_CNN_Transformer().cuda()\n","# model.load_state_dict(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["answers = []\n","for i in range(len(y_train_secondtest)):\n","  test_record = np.load('/kaggle/input/datasetfinalstest/test/'+record_names[i]+'.npy')\n","  test_record = scaler.transform(test_record)\n","\n","  answers.append(inference_ov(model, torch.from_numpy(test_record).cuda()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reses = [1 if float(j) >= 0.275 else 0 for j in list(eval_res)]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","dsTrue = pd.read_csv('/kaggle/input/datasetfinals/train/train_gts_final.csv')\n","dsTrue"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dsTrue.set_index('record_name', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import math\n","def sigmoid(x):\n","    return 1 / (1 + math.exp(-x))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_arr = []\n","for k in range(len(answers)):\n","    for j in range(len(answers[k])):\n","        new_arr.append(answers[k][j].detach().cpu().numpy())\n","\n","for i in range(len(new_arr)):\n","    for j in range(len(new_arr[i])):\n","        try:\n","            new_arr[i][j] = sigmoid(new_arr[i][j])\n","        except:\n","            new_arr[i][j] = 0\n","\n","ress = []\n","for kk in range(len(reses)):\n","    if reses[kk] == 0:\n","        ress.append([0,0,0,0,0,0,1])\n","    else:\n","#         tmp_ress = [1 if float(j) >= 0.1 else 0 for j in new_arr[kk]]+[0]\n","#         count_zero = 0\n","#         for ll in tmp_ress:\n","#             if ll == 0:\n","#                 count_zero += 1            использование максимального элемента вместо трешхолда [1, 2, 3] -> [0, 0, 1]\n","#         if count_zero == 7:                не привело к хорошим результатам\n","#             print(new_arr[kk].shape)\n","#             zero_mat = np.zeros(new_arr[kk].shape[0] + 1)\n","#             zero_mat[np.argmax(new_arr[kk], axis = 0)] = 1\n","# #             print(zero_mat)\n","# #             print(new_arr[kk])\n","# #             print(kk)\n","# #             break\n","#             ress.append(zero_mat.astype(int))\n","#             print(kk)\n","#         else:\n","\n","        ress.append([1 if float(j) >= 0.1 else 0 for j in new_arr[kk]]+[0])\n","ans = pd.DataFrame(ress, columns = list(dsTrue.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ans['record_name'] = record_names\n","ans.set_index('record_name', inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sample = pd.read_csv('/kaggle/input/sample/sample_submission (5).csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(len(sample)):\n","    sample.loc[i, 'перегородочный'] = ans.loc[sample.iloc[i]['record_name']]['перегородочный'] \n","    sample.loc[i, 'передний'] = ans.loc[sample.iloc[i]['record_name']]['передний']\n","    sample.loc[i, 'боковой'] = ans.loc[sample.iloc[i]['record_name']]['боковой'] \n","    sample.loc[i, 'передне-боковой'] = ans.loc[sample.iloc[i]['record_name']]['передне-боковой'] \n","    sample.loc[i, 'передне-перегородочный'] = ans.loc[sample.iloc[i]['record_name']]['передне-перегородочный'] \n","    sample.loc[i, 'нижний'] = ans.loc[sample.iloc[i]['record_name']]['нижний'] \n","    sample.loc[i, 'норма'] = ans.loc[sample.iloc[i]['record_name']]['норма'] "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sample.to_csv('bestansesBIN+FULLf10.54loss0.05classes6Threshold01andOV0875.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["**ИСТОРИЯ РАБОТЫ (СКОПИРОВАНЫ ИЗ ДРУГИХ БЛОКНОТОВ)**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["###АЛГОРИТМ ПЕРЕБОРА ЛУЧШЕГО ТРЕШХОЛДА\n","\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","predictions = [preds_class[i][1]*0.8 + 0.4*sigmoid(preds_graph[i]) for i in range(len(preds_class))]\n","labels = train_Y\n","\n","from sklearn.metrics import f1_score\n","\n","def find_best_threshold(y_true, y_proba):\n","    thresholds = np.arange(0.0, 1.0, 0.001)\n","    best_f1 = 0\n","    best_threshold = 0\n","\n","    for threshold in thresholds:\n","        y_pred = [1 if prob >= threshold else 0 for prob in y_proba]\n","        f1 = f1_score(y_true, y_pred)\n","\n","        if f1 > best_f1:\n","            best_f1 = f1\n","            best_threshold = threshold\n","    print(best_f1)\n","    return best_threshold\n","\n","best_threshold = find_best_threshold(labels, predictions)\n","print(best_threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class F1Loss(nn.Module):\n","    def __init__(self, epsilon=1e-7):\n","        super().__init__()\n","        self.epsilon = epsilon\n","        \n","    def forward(self, y_pred, y_true):\n","        # Преобразование предсказаний в бинарные значения\n","        y_pred = torch.round(torch.sigmoid(y_pred))  # добавляем sigmoid, если не использовали его ранее\n","        \n","        # Вычисление TP, FP, FN\n","        tp = torch.sum(y_true * y_pred, dim=1)\n","        fp = torch.sum((1 - y_true) * y_pred, dim=1)\n","        fn = torch.sum(y_true * (1 - y_pred), dim=1)\n","\n","        # Вычисление precision и recall\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        # Вычисление F1 Score\n","        f1_score = 2 * (precision * recall) / (precision + recall + self.epsilon)\n","\n","        # Возвращение F1 loss: 1 - среднее значение F1 Score\n","        return 1 - torch.mean(f1_score)"]},{"cell_type":"markdown","metadata":{},"source":["**ИСПРОБОВАННЫЕ ВАРИАНТЫ pytorch моделей**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ECG_CNN_Transformer(nn.Module):\n","    def __init__(self):\n","        super(ECG_CNN_Transformer, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=12, out_channels=64, kernel_size=7, padding=3)\n","        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n","        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1,)\n","        \n","        self.encoder_layer = nn.TransformerEncoderLayer(d_model=12, nhead=3)  ### (1 - 3)\n","        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2) ### (1 - 2)\n","        #+ 64*1000\n","        self.fc1 = nn.Linear(256*700 + 12*700 , 128) # Concatenating output of CNN and Transformer\n","        self.fc2 = nn.Linear(128, 6)\n","        self.relu = nn.ReLU()\n","        self.sig = nn.Sigmoid()\n","        self.drop = nn.Dropout(0.2)\n","        self.drop5 = nn.Dropout(0.8)\n","\n","    def forward(self, x):\n","        cnn_x = self.relu(self.conv1(x))\n","        cnn_x = self.relu(self.conv2(cnn_x))\n","        cnn_x = self.relu(self.conv3(cnn_x))\n","        cnn_x = cnn_x.view(x.size(0), -1) # flatten the tensor\n","        \n","        #cnn_xf = self.relu(self.conv1(full_x))\n","        #cnn_xf = cnn_xf.view(full_x.size(0), -1) # flatten the tensor\n","        #cnn_xf = self.drop5(cnn_xf)\n","\n","        x = x.permute(2, 0, 1)  # Transformer expects input as (seq_len, batch, features)\n","        transformer_x = self.transformer_encoder(x)\n","        transformer_x = transformer_x.permute(1, 0, 2)  # Back to (batch, seq_len, features)\n","        transformer_x = transformer_x.reshape(transformer_x.size(0), -1)  # flatten the tensor\n","        #transformer_x = self.drop(transformer_x)\n","\n","        # Concatenate CNN and Transformer outputs\n","        x = torch.cat((cnn_x, transformer_x), dim=1)\n","\n","        x = self.relu(self.fc1(x))\n","        #x = self.drop(x)\n","        x = self.fc2(x)\n","        #x = self.sig(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AggregatingLSTMClassifier(nn.Module):\n","    def __init__(self, input_dim=12, hidden_dim=5, output_dim=1, num_layers=5):\n","        super().__init__()\n","\n","        self.lstm = nn.Transformer(input_dim, hidden_dim, num_layers, batch_first=True)\n","        self.fc = nn.Linear(input_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, x):\n","\n","        lstm_out, _ = self.lstm(x.permute(0, 1, 2))\n","\n","\n","        out = self.fc(lstm_out)\n","        out = self.sig(out).mean(dim=1)\n","\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TransformerClassifier(nn.Module):\n","    def __init__(self, input_dim=12, hidden_dim=5, output_dim=1, num_layers=5):\n","        super().__init__()\n","\n","        self.transformer = nn.TransformerEncoderLayer(input_dim, num_layers, dropout=0.1)\n","        self.fc = nn.Linear(input_dim, output_dim)\n","        self.fc2 = nn.Linear(5000, 1)\n","        self.sig = nn.Sigmoid()\n","        self.dp = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        transformer_out = self.transformer(x.permute(0, 2, 1))\n","\n","        out = self.fc(transformer_out)\n","\n","        out = self.fc2(out.permute(0,2,1))\n","        out = self.sig(out)\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AggregatingEmbedLSTMClassifier(nn.Module):\n","    def __init__(self, input_dim=12, hidden_dim=5, output_dim=1, num_layers=5):\n","        super().__init__()\n","        self.embedding = nn.Embedding(5000,32)\n","        self.lstm = nn.LSTM(32, 5, 5, batch_first=True,bidirectional = False)\n","        self.fc = nn.Linear(input_dim, output_dim)\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        embed_out = self.embedding(x.permute(0, 1, 2))\n","        lstm_out, _ = self.lstm(embed_out)\n","\n","\n","        out = self.fc(lstm_out)\n","        out = self.sig(out).mean(dim=1)\n","\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ECG_CNN(nn.Module):\n","    def __init__(self):\n","        super(ECG_CNN, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=12, out_channels=64, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1,)\n","        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1,)\n","        self.fc1 = nn.Linear(256*800, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.relu = nn.ReLU()\n","        self.sig = nn.Sigmoid()\n","        self.drop = nn.Dropout(0.2)\n","\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        #x = self.drop(x)\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.drop(x)\n","        x = self.fc2(x)\n","        x = self.sig(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ECG_CNN_slice(nn.Module):\n","    def __init__(self):\n","        super(ECG_CNN_slice, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=12, out_channels=64, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1,)\n","        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1,)\n","        self.fc1 = nn.Linear(256*850, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.relu = nn.ReLU()\n","        self.sig = nn.Sigmoid()\n","        self.drop = nn.Dropout(0.2)\n","\n","    def forward(self, x):\n","        x = self.slice(x)\n","        # print(x.shape)\n","        # print(1/0)\n","        x = self.relu(self.conv1(x))\n","        #x = self.drop(x)\n","        x = self.relu(self.conv2(x))\n","        x = self.relu(self.conv3(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.drop(x)\n","        x = self.fc2(x)\n","        x = self.sig(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","class ECG_Transformer(nn.Module):\n","    def __init__(self):\n","        super(ECG_Transformer, self).__init__()\n","        self.embedding = nn.Linear(12, 64)\n","        encoder_layers = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=3)\n","        self.fc = nn.Linear(64, 1)\n","        self.sig = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = x.permute(2, 0, 1)\n","        x = self.embedding(x)\n","        x = self.transformer_encoder(x)\n","        x = x.permute(1, 2, 0)\n","        x = torch.mean(x, dim=2)\n","        x = self.fc(x)\n","        x = self.sig(x)\n","        return x"]}],"metadata":{"kernelspec":{"display_name":"","name":""},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":4}
